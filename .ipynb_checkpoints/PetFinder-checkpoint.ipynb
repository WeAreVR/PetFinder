{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf290555",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ~\\.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff5e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ~\\.kaggle && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a43c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c petfinder-pawpularity-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4284de58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd203408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "tf.config.run_functions_eagerly(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91845223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import af libaries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import tensorflow_addons as tfa\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import imageio\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9201a67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of tranning's data: 9912\n"
     ]
    }
   ],
   "source": [
    "#test is not working i need to have a look at the download again\n",
    "train = pd.read_csv('train.csv')\n",
    "#test = pd.read_csv('test.csv')\n",
    "print(\"Amount of tranning's data: \" + str(len(train)))\n",
    "#print(\"Amount of test data: \" + str(len(test)))\n",
    "image_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b833ec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>C:\\Users\\tobia\\GitHub\\PetFinder\\train\\0007de18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>C:\\Users\\tobia\\GitHub\\PetFinder\\train\\0009c66b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>C:\\Users\\tobia\\GitHub\\PetFinder\\train\\0013fd99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>C:\\Users\\tobia\\GitHub\\PetFinder\\train\\0018df34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>C:\\Users\\tobia\\GitHub\\PetFinder\\train\\001dc955...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  0007de18844b0dbbb5e1f607da0606e0              0     1     1     1       0   \n",
       "1  0009c66b9439883ba2750fb825e1d7db              0     1     1     0       0   \n",
       "2  0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1       0   \n",
       "3  0018df346ac9c1d8413cfcc888ca8246              0     1     1     1       0   \n",
       "4  001dc955e10590d3ca4673f034feeef2              0     0     0     1       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  Pawpularity  \\\n",
       "0          0      1        0      0          0     0     0           63   \n",
       "1          0      0        0      0          0     0     0           42   \n",
       "2          0      0        0      1          1     0     0           28   \n",
       "3          0      0        0      0          0     0     0           15   \n",
       "4          0      1        0      0          0     0     0           72   \n",
       "\n",
       "                                           file_path  \n",
       "0  C:\\Users\\tobia\\GitHub\\PetFinder\\train\\0007de18...  \n",
       "1  C:\\Users\\tobia\\GitHub\\PetFinder\\train\\0009c66b...  \n",
       "2  C:\\Users\\tobia\\GitHub\\PetFinder\\train\\0013fd99...  \n",
       "3  C:\\Users\\tobia\\GitHub\\PetFinder\\train\\0018df34...  \n",
       "4  C:\\Users\\tobia\\GitHub\\PetFinder\\train\\001dc955...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loading images\n",
    "def get_train_file_path(image_id):\n",
    "    return r\"C:\\Users\\tobia\\GitHub\\PetFinder\\train\\{}.jpg\".format(image_id)\n",
    "\n",
    "def get_test_file_path(image_id):\n",
    "    return r\"C:\\Users\\tobia\\GitHub\\PetFinder\\test\\{}.jpg\".format(image_id)\n",
    "\n",
    "train['file_path'] = train['Id'].apply(get_train_file_path)\n",
    "#test['file_path'] = test['Id'].apply(get_test_file_path)\n",
    "\n",
    "\n",
    "# Shows the first 5, change the paramter for more\n",
    "display(train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce312d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the spread??\n",
    "train.hist(figsize=(15,15))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a419be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean of Pawpularity remove [] if you want the see mean on everything\n",
    "print(\"Mean value of train \"+ str(train['Pawpularity'].mean()))\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4065438",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Kinda slow might be a faster way to do it.\n",
    "#It gets height and width of each image and then calculate the aspect ratio\n",
    "widths = []\n",
    "heights = []\n",
    "ratios = []\n",
    "for file_path in tqdm(train['file_path']):\n",
    "    image = imageio.imread(file_path)\n",
    "    h, w, _ = image.shape\n",
    "    heights.append(h)\n",
    "    widths.append(w)\n",
    "    ratios.append(w / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we plot it to see the values\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title(f'Height and Width', size=24)\n",
    "plt.hist(heights, bins=32, label='Heights')\n",
    "plt.hist(widths, bins=32, label='Widths')\n",
    "plt.legend(prop={'size': 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/markwijkhuizen/petfinder-eda-yolov5-obj-detection-tfrecords#Image-EDA\n",
    "#Fyld ud med grå\n",
    "display(pd.Series(ratios).describe())\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title(f'Ratios', size=24)\n",
    "plt.hist(ratios, bins=15, label='Ratios')\n",
    "plt.legend(prop={'size': 15})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78663178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hard to see the coalition on the ???bar??? graph so we create a scatter point graph\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "points = ax.scatter(widths, heights, color='blue', alpha=0.5, s=ratios, picker=True)\n",
    "ax.set_title(\"Image Resolution\")\n",
    "ax.set_xlabel(\"Width\", size=14)\n",
    "ax.set_ylabel(\"Height\", size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df82fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shows 5x5 images and their title is their paw score\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(5 * 5):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    image = plt.imread(train.iloc[i, -1])\n",
    "    #image = plt.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    Pawpularity = train.iloc[i, -2]\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Pawpularity Score: {Pawpularity}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17017d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ligner der er duplicates som skal fjernes \n",
    "#https://www.kaggle.com/c/petfinder-pawpularity-score/discussion/278497 kode til at fjerne dem findes her\n",
    "tqdm.pandas()\n",
    "def get_hash(file_path):\n",
    "    img = Image.open(file_path)\n",
    "    img_hash = imagehash.phash(img)\n",
    "    \n",
    "    return img_hash.hash.reshape(-1).astype(np.uint8)\n",
    "    \n",
    "train['phash'] = train['file_path'].progress_apply(get_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5486f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_images(threshold=0.90):\n",
    "    # Number of Duplicate Images Found\n",
    "    duplicate_counter = 1\n",
    "    # Indices of Duplicate Images\n",
    "    duplicate_idxs = set()\n",
    "    # For each image in the train dataset\n",
    "    for idx, phash in enumerate(tqdm(train['phash'])):\n",
    "        # Compute the similarity to all other images\n",
    "        for idx_other, phash_other in enumerate(train['phash']):\n",
    "            # Similarity score is imply the percentage of equal bits\n",
    "            similarity = (phash ==phash_other).mean()\n",
    "            # Prevent self comparison, threshold similarity and ignore repetetive duplicate detection\n",
    "            if idx != idx_other and similarity > threshold and not(duplicate_idxs.intersection([idx, idx_other])):\n",
    "                # Update Duplicate Indices\n",
    "                duplicate_idxs.update([idx, idx_other])\n",
    "                # Get DataFrame rows\n",
    "                row = train.loc[idx]\n",
    "                row_other = train.loc[idx_other]\n",
    "                # Plot Duplicate Images\n",
    "                fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8,5))\n",
    "                ax[0].imshow(imageio.imread(row['file_path']))\n",
    "                ax[0].set_title(f'Idx: {idx}, Pawpularity: {row[\"Pawpularity\"]}')\n",
    "                ax[1].imshow(imageio.imread(row_other['file_path']))\n",
    "                ax[1].set_title(f'Idx: {idx_other}, Pawpularity: {row_other[\"Pawpularity\"]}')\n",
    "                plt.suptitle(f'{duplicate_counter} | PHASH Similarity: {similarity:.3f}')\n",
    "                plt.show()\n",
    "                # Increase Duplicate Counter\n",
    "                duplicate_counter += 1\n",
    "                \n",
    "    # Return Indices of Duplicates\n",
    "    return duplicate_idxs\n",
    "    \n",
    "duplicate_idxs = find_similar_images()\n",
    "#The same images don't have the same paw score. The majority's paw score's diffrence is around 10.\n",
    "#But some got over double the score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd705326",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Found {len(duplicate_idxs)} Duplicate Images')\n",
    "# Removing Duplicate Images, \n",
    "#Code taken from https://www.kaggle.com/markwijkhuizen/petfinder-eda-yolov5-obj-detection-tfrecords#Image-EDA\n",
    "#IMPORTANT(I think so atleast)! If this code is run twice it will drop both images instead of just one of the duplicates\n",
    "#Hhich image is correct one? They got diffrent scores\n",
    "train = train.drop(duplicate_idxs).reset_index(drop=True)\n",
    "print(\"Amount of tranning's data: \" + str(len(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2732a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows a batch of images we will use this function to see the lowest and highest pawpularity\n",
    "def show_batch_df(df, rows=6, cols=4):\n",
    "    df = df.copy().reset_index()\n",
    "    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(cols*4, rows*4))\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            idx = r * cols + c\n",
    "            img = imageio.imread(df.loc[idx, 'file_path'])\n",
    "            plt.imshow(img)\n",
    "            axes[r, c].set_title(f'{idx}, label: {df.loc[idx, \"Pawpularity\"]}')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1938aa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Images with the lowest value\n",
    "sorted_lowest = (train.sort_values('Pawpularity'))\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(5 * 5):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    image = plt.imread(sorted_lowest.iloc[i, -1])\n",
    "    Pawpularity = sorted_lowest.iloc[i, -2]\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Pawpularity Score: {Pawpularity}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a9fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Images with the highest value\n",
    "sorted_highest = (train.sort_values('Pawpularity',ascending=False))\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(5 * 5):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    image = plt.imread(sorted_highest.iloc[i, -1])\n",
    "    Pawpularity = sorted_highest.iloc[i, -2]\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Pawpularity Score: {Pawpularity}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "962c3b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need some more preproccsing and data normalization\n",
    "def dataNormalization(image):\n",
    "    image = Image.open(image)\n",
    "    #tf.image.convert_image_dtype(image, tf.float32)\n",
    "    #image = tf.reshape(image, [352, 352, 3])\n",
    "    image = tf.image.resize(image, (image_size, image_size))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcf4e163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of tranning's data: 7929\n",
      "Amount of test data: 1983\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19108/2833176227.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Amount of test data: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtrain_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'file_path'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataNormalization\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'file_path'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataNormalization\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   4159\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4160\u001b[0m         \"\"\"\n\u001b[1;32m-> 4161\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4162\u001b[0m         return self._constructor(new_values, index=self.index).__finalize__(\n\u001b[0;32m   4163\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"map\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_map_values\u001b[1;34m(self, mapper, na_action)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;31m# mapper is a function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 870\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19108/1380516194.py\u001b[0m in \u001b[0;36mdataNormalization\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#tf.image.convert_image_dtype(image, tf.float32)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#image = tf.reshape(image, [352, 352, 3])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py\u001b[0m in \u001b[0;36mresize_images_v2\u001b[1;34m(images, size, method, preserve_aspect_ratio, antialias, name)\u001b[0m\n\u001b[0;32m   1715\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Resize method is not implemented: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1717\u001b[1;33m   return _resize_images_common(\n\u001b[0m\u001b[0;32m   1718\u001b[0m       \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1719\u001b[0m       \u001b[0mresize_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py\u001b[0m in \u001b[0;36m_resize_images_common\u001b[1;34m(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same)\u001b[0m\n\u001b[0;32m   1385\u001b[0m   \u001b[1;34m\"\"\"Core functionality for v1 and v2 resize functions.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'resize'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1387\u001b[1;33m     \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'images'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1388\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1389\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\'images\\' contains no shape.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1566\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    344\u001b[0m                                          as_ref=False):\n\u001b[0;32m    345\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m--> 271\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    281\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m   \u001b[1;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "#train['file_path'] = train['file_path'].apply(dataNormalization)\n",
    "#image = plt.imread(train.loc[0,'file_path'])\n",
    "#ds = tf.data.Dataset.from_tensor_slices(dict(train))\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "#opdel i test og train\n",
    "train, test = train_test_split(train, test_size=0.2)\n",
    "print(\"Amount of tranning's data: \" + str(len(train)))\n",
    "print(\"Amount of test data: \" + str(len(test)))\n",
    "\n",
    "train_dataset = train['file_path'].map(dataNormalization)\n",
    "test_dataset = test['file_path'].map(dataNormalization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f90db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks if the values are normalized\n",
    "#print(train_dataset[0])\n",
    "#we need proper names here\n",
    "train_pred = train.loc[:,'Pawpularity']\n",
    "test_pred = test.loc[:,'Pawpularity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccea9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_pred)\n",
    "#type(pred)\n",
    "#result = pd.merge(train_dataset, pred, left_on=None)\n",
    "#train_dataset = pd.merge(train_dataset, train_pred, left_index=True, right_index=True)\n",
    "#test_dataset = pd.merge(test_dataset, test_pred, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eee657",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.loc[2, 'file_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce453a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_dataset.head())\n",
    "\n",
    "#print(train_dataset['file_path'])\n",
    "#display(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beb4559",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(5 * 5):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.title('Original image')\n",
    "    image = train_dataset.iloc[i, 0]\n",
    "    plt.imshow(image)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2414e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Side by side comparrison with the new ratio\n",
    "result_image = train_dataset.iloc[0, 0]\n",
    "train_image = plt.imread(train.iloc[0, -1])\n",
    "visualize(train_image,result_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b2dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(augmented):\n",
    "    # We need to test with the diffrent type of augment to see if they hurt the acc. \n",
    "    # We should also take some of the fuctions we used in CNN\n",
    "    augmented = tf.image.random_brightness(augmented, 0.05)\n",
    "    augmented = tf.image.random_flip_left_right(augmented)\n",
    "    augmented = tf.image.random_saturation(augmented, 0.95, 1)\n",
    "    augmented = tf.image.random_contrast(augmented, 0.95, 1)\n",
    "    augmented = tf.image.random_hue(augmented, 0.05)\n",
    "    augmented = shear(augmented)\n",
    "    return augmented\n",
    "\n",
    "def visualize(original, augmented):\n",
    "    fig = plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('Original image')\n",
    "    plt.imshow(original)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('Augmented image')\n",
    "    plt.imshow(augmented)\n",
    "    \n",
    "def shear(image):\n",
    "    #shear\n",
    "    #de her værdier skal nok ændres i\n",
    "    random_number_shear = random.uniform(-0.2,0.2)\n",
    "    shear = random_number_shear\n",
    "    shear_rotate = shear * -20\n",
    "    image = tfa.image.transform(image, [1.0, shear, shear_rotate, 0.0, 1.0, 0.0, 0.0, 0.0])\n",
    "    return image\n",
    "\n",
    "def crop(image):\n",
    "    # Add 6 pixels of padding\n",
    "    image = tf.image.resize_with_crop_or_pad(image, img_height + 6, img_width + 6) \n",
    "    # Random crop back to the original size\n",
    "    image = tf.image.random_crop(image, size=[img_height, img_width, 1])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0fcbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    image = train_dataset.iloc[i, 0]\n",
    "    changed_image = augment(image)\n",
    "    visualize(image,changed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First model\n",
    "model = tf.keras.models.Sequential([\n",
    "layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
    "layers.Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "layers.MaxPool2D(pool_size=2, strides=2),\n",
    "layers.Dropout(0.25),\n",
    "layers.Conv2D(filters=128, kernel_size=3, activation='relu'),\n",
    "layers.MaxPool2D(pool_size=2, strides=2),\n",
    "layers.Conv2D(filters=128, kernel_size=3, activation='relu'),\n",
    "layers.MaxPool2D(pool_size=2, strides=2),\n",
    "layers.Dropout(0.25),\n",
    "layers.Flatten(),\n",
    "layers.Dense(units=1024, activation='relu'),\n",
    "layers.Dropout(0.50),\n",
    "layers.Dense(units=1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.MeanSquaredError(),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8c5794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_dataset.shape)\n",
    "#print(test_dataset.shape)\n",
    "#print(train_dataset)\n",
    "def labelNormalize(value):\n",
    "    return value/100;\n",
    "train_pred = train_pred.map(labelNormalize)\n",
    "print(train_pred)\n",
    "#test_dataset.dtypes\n",
    "X = np.array(train_dataset.tolist())\n",
    "#clf.fit(test_dataset[0].tolist(), labels)\n",
    "#np.array(test_dataset).astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e07ab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.size)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f27c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_dataset)\n",
    "#df[df['price'] < 50000]\n",
    "#https://www.kaggle.com/questions-and-answers/50121\n",
    "\n",
    "#train_dataset.loc[(train_dataset[\"Pawpularity\"]<=100)|train_dataset[\"Pawpularity\"]>0]\n",
    "#test_dataset.loc[(test_dataset[\"Pawpularity\"]<=100)|test_dataset[\"Pawpularity\"]>0]\n",
    "\n",
    "\n",
    "#intet virker og jeg er trist del op uden merge i x-y_pred\n",
    "#We need to batch the data aswell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafe5af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X,train_pred, epochs = 5)\n",
    "#fit(\n",
    "#    x=None, y=None, batch_size=None, epochs=1, verbose='auto',\n",
    "#    callbacks=None, validation_split=0.0, validation_data=None, shuffle=True,\n",
    "#    class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None,\n",
    "#    validation_steps=None, validation_batch_size=None, validation_freq=1,\n",
    "#    max_queue_size=10, workers=1, use_multiprocessing=False\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35891fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

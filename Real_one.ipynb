{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf290555",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ~\\.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff5e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ~\\.kaggle && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a43c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c petfinder-pawpularity-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4284de58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd203408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "tf.config.run_functions_eagerly(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91845223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import af libaries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import tensorflow_addons as tfa\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import imageio\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9201a67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of tranning's data: 9912\n"
     ]
    }
   ],
   "source": [
    "#test is not working i need to have a look at the download again\n",
    "train = pd.read_csv('train.csv')\n",
    "#test = pd.read_csv('test.csv')\n",
    "print(\"Amount of tranning's data: \" + str(len(train)))\n",
    "#print(\"Amount of test data: \" + str(len(test)))\n",
    "image_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b833ec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>C:\\Users\\tobia\\GitHub\\PetFinder\\train\\0007de18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>C:\\Users\\tobia\\GitHub\\PetFinder\\train\\0009c66b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>C:\\Users\\tobia\\GitHub\\PetFinder\\train\\0013fd99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>C:\\Users\\tobia\\GitHub\\PetFinder\\train\\0018df34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>C:\\Users\\tobia\\GitHub\\PetFinder\\train\\001dc955...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  0007de18844b0dbbb5e1f607da0606e0              0     1     1     1       0   \n",
       "1  0009c66b9439883ba2750fb825e1d7db              0     1     1     0       0   \n",
       "2  0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1       0   \n",
       "3  0018df346ac9c1d8413cfcc888ca8246              0     1     1     1       0   \n",
       "4  001dc955e10590d3ca4673f034feeef2              0     0     0     1       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  Pawpularity  \\\n",
       "0          0      1        0      0          0     0     0           63   \n",
       "1          0      0        0      0          0     0     0           42   \n",
       "2          0      0        0      1          1     0     0           28   \n",
       "3          0      0        0      0          0     0     0           15   \n",
       "4          0      1        0      0          0     0     0           72   \n",
       "\n",
       "                                           file_path  \n",
       "0  C:\\Users\\tobia\\GitHub\\PetFinder\\train\\0007de18...  \n",
       "1  C:\\Users\\tobia\\GitHub\\PetFinder\\train\\0009c66b...  \n",
       "2  C:\\Users\\tobia\\GitHub\\PetFinder\\train\\0013fd99...  \n",
       "3  C:\\Users\\tobia\\GitHub\\PetFinder\\train\\0018df34...  \n",
       "4  C:\\Users\\tobia\\GitHub\\PetFinder\\train\\001dc955...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loading images\n",
    "def get_train_file_path(image_id):\n",
    "    return r\"C:\\Users\\tobia\\GitHub\\PetFinder\\train\\{}.jpg\".format(image_id)\n",
    "\n",
    "def get_test_file_path(image_id):\n",
    "    return r\"C:\\Users\\tobia\\GitHub\\PetFinder\\test\\{}.jpg\".format(image_id)\n",
    "\n",
    "train['file_path'] = train['Id'].apply(get_train_file_path)\n",
    "#test['file_path'] = test['Id'].apply(get_test_file_path)\n",
    "\n",
    "\n",
    "# Shows the first 5, change the paramter for more\n",
    "display(train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce312d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the spread??\n",
    "train.hist(figsize=(15,15))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a419be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean of Pawpularity remove [] if you want the see mean on everything\n",
    "print(\"Mean value of train \"+ str(train['Pawpularity'].mean()))\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4065438",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Kinda slow might be a faster way to do it.\n",
    "#It gets height and width of each image and then calculate the aspect ratio\n",
    "widths = []\n",
    "heights = []\n",
    "ratios = []\n",
    "for file_path in tqdm(train['file_path']):\n",
    "    image = imageio.imread(file_path)\n",
    "    h, w, _ = image.shape\n",
    "    heights.append(h)\n",
    "    widths.append(w)\n",
    "    ratios.append(w / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we plot it to see the values\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title(f'Height and Width', size=24)\n",
    "plt.hist(heights, bins=32, label='Heights')\n",
    "plt.hist(widths, bins=32, label='Widths')\n",
    "plt.legend(prop={'size': 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/markwijkhuizen/petfinder-eda-yolov5-obj-detection-tfrecords#Image-EDA\n",
    "display(pd.Series(ratios).describe())\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title(f'Ratios', size=24)\n",
    "plt.hist(ratios, bins=15, label='Ratios')\n",
    "plt.legend(prop={'size': 15})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78663178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hard to see the coalition on the ???bar??? graph so we create a scatter point graph\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "points = ax.scatter(widths, heights, color='blue', alpha=0.5, s=ratios, picker=True)\n",
    "ax.set_title(\"Image Resolution\")\n",
    "ax.set_xlabel(\"Width\", size=14)\n",
    "ax.set_ylabel(\"Height\", size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df82fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shows 5x5 images and their title is their paw score\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(5 * 5):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    image = plt.imread(train.iloc[i, -1])\n",
    "    #image = plt.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    Pawpularity = train.iloc[i, -2]\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Pawpularity Score: {Pawpularity}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17017d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ligner der er duplicates som skal fjernes \n",
    "#https://www.kaggle.com/c/petfinder-pawpularity-score/discussion/278497 kode til at fjerne dem findes her\n",
    "tqdm.pandas()\n",
    "def get_hash(file_path):\n",
    "    img = Image.open(file_path)\n",
    "    img_hash = imagehash.phash(img)\n",
    "    \n",
    "    return img_hash.hash.reshape(-1).astype(np.uint8)\n",
    "    \n",
    "train['phash'] = train['file_path'].progress_apply(get_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5486f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_images(threshold=0.90):\n",
    "    # Number of Duplicate Images Found\n",
    "    duplicate_counter = 1\n",
    "    # Indices of Duplicate Images\n",
    "    duplicate_idxs = set()\n",
    "    # For each image in the train dataset\n",
    "    for idx, phash in enumerate(tqdm(train['phash'])):\n",
    "        # Compute the similarity to all other images\n",
    "        for idx_other, phash_other in enumerate(train['phash']):\n",
    "            # Similarity score is imply the percentage of equal bits\n",
    "            similarity = (phash ==phash_other).mean()\n",
    "            # Prevent self comparison, threshold similarity and ignore repetetive duplicate detection\n",
    "            if idx != idx_other and similarity > threshold and not(duplicate_idxs.intersection([idx, idx_other])):\n",
    "                # Update Duplicate Indices\n",
    "                duplicate_idxs.update([idx, idx_other])\n",
    "                # Get DataFrame rows\n",
    "                row = train.loc[idx]\n",
    "                row_other = train.loc[idx_other]\n",
    "                # Plot Duplicate Images\n",
    "                fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8,5))\n",
    "                ax[0].imshow(imageio.imread(row['file_path']))\n",
    "                ax[0].set_title(f'Idx: {idx}, Pawpularity: {row[\"Pawpularity\"]}')\n",
    "                ax[1].imshow(imageio.imread(row_other['file_path']))\n",
    "                ax[1].set_title(f'Idx: {idx_other}, Pawpularity: {row_other[\"Pawpularity\"]}')\n",
    "                plt.suptitle(f'{duplicate_counter} | PHASH Similarity: {similarity:.3f}')\n",
    "                plt.show()\n",
    "                # Increase Duplicate Counter\n",
    "                duplicate_counter += 1\n",
    "                \n",
    "    # Return Indices of Duplicates\n",
    "    return duplicate_idxs\n",
    "    \n",
    "duplicate_idxs = find_similar_images()\n",
    "#The same images don't have the same paw score. The majority's paw score's diffrence is around 10.\n",
    "#But some got over double the score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd705326",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Found {len(duplicate_idxs)} Duplicate Images')\n",
    "# Removing Duplicate Images, \n",
    "#Code taken from https://www.kaggle.com/markwijkhuizen/petfinder-eda-yolov5-obj-detection-tfrecords#Image-EDA\n",
    "#IMPORTANT(I think so atleast)! If this code is run twice it will drop both images instead of just one of the duplicates\n",
    "#Hhich image is correct one? They got diffrent scores\n",
    "train = train.drop(duplicate_idxs).reset_index(drop=True)\n",
    "print(\"Amount of tranning's data: \" + str(len(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2732a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows a batch of images we will use this function to see the lowest and highest pawpularity\n",
    "def show_batch_df(df, rows=6, cols=4):\n",
    "    df = df.copy().reset_index()\n",
    "    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(cols*4, rows*4))\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            idx = r * cols + c\n",
    "            img = imageio.imread(df.loc[idx, 'file_path'])\n",
    "            plt.imshow(img)\n",
    "            axes[r, c].set_title(f'{idx}, label: {df.loc[idx, \"Pawpularity\"]}')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1938aa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Images with the lowest value\n",
    "sorted_lowest = (train.sort_values('Pawpularity'))\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(5 * 5):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    image = plt.imread(sorted_lowest.iloc[i, -1])\n",
    "    Pawpularity = sorted_lowest.iloc[i, -2]\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Pawpularity Score: {Pawpularity}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a9fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Images with the highest value\n",
    "sorted_highest = (train.sort_values('Pawpularity',ascending=False))\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(5 * 5):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    image = plt.imread(sorted_highest.iloc[i, -1])\n",
    "    Pawpularity = sorted_highest.iloc[i, -2]\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Pawpularity Score: {Pawpularity}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "962c3b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need some more preproccsing and data normalization\n",
    "def dataNormalization(image):\n",
    "    image = Image.open(image)\n",
    "    #tf.image.convert_image_dtype(image, tf.float32)\n",
    "    #image = tf.reshape(image, [352, 352, 3])\n",
    "    image = tf.image.resize(image, (image_size, image_size))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcf4e163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of tranning's data: 7929\n",
      "Amount of test data: 1983\n"
     ]
    }
   ],
   "source": [
    "#train['file_path'] = train['file_path'].apply(dataNormalization)\n",
    "#image = plt.imread(train.loc[0,'file_path'])\n",
    "#ds = tf.data.Dataset.from_tensor_slices(dict(train))\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "#opdel i test og train\n",
    "train, test = train_test_split(train, test_size=0.2)\n",
    "print(\"Amount of tranning's data: \" + str(len(train)))\n",
    "print(\"Amount of test data: \" + str(len(test)))\n",
    "\n",
    "train_dataset = train['file_path'].map(dataNormalization)\n",
    "test_dataset = test['file_path'].map(dataNormalization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f90db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks if the values are normalized\n",
    "#print(train_dataset[0])\n",
    "#we need proper names here\n",
    "train_pred = train.loc[:,'Pawpularity']\n",
    "test_pred = test.loc[:,'Pawpularity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ccea9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7413    51\n",
      "995     29\n",
      "1970    62\n",
      "4393    27\n",
      "9842    30\n",
      "        ..\n",
      "4508     9\n",
      "5918    65\n",
      "4463    68\n",
      "3347    25\n",
      "2643    84\n",
      "Name: Pawpularity, Length: 7929, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_pred)\n",
    "#type(pred)\n",
    "#result = pd.merge(train_dataset, pred, left_on=None)\n",
    "#train_dataset = pd.merge(train_dataset, train_pred, left_index=True, right_index=True)\n",
    "#test_dataset = pd.merge(test_dataset, test_pred, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90eee657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7413    (((tf.Tensor(0.26078433, shape=(), dtype=float...\n",
      "995     (((tf.Tensor(0.19353554, shape=(), dtype=float...\n",
      "1970    (((tf.Tensor(0.16565947, shape=(), dtype=float...\n",
      "4393    (((tf.Tensor(0.19068627, shape=(), dtype=float...\n",
      "9842    (((tf.Tensor(0.7561275, shape=(), dtype=float3...\n",
      "                              ...                        \n",
      "4508    (((tf.Tensor(0.12990196, shape=(), dtype=float...\n",
      "5918    (((tf.Tensor(0.15784314, shape=(), dtype=float...\n",
      "4463    (((tf.Tensor(0.6057866, shape=(), dtype=float3...\n",
      "3347    (((tf.Tensor(0.74509805, shape=(), dtype=float...\n",
      "2643    (((tf.Tensor(0.084803924, shape=(), dtype=floa...\n",
      "Name: file_path, Length: 7929, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ce453a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7413    (((tf.Tensor(0.26078433, shape=(), dtype=float...\n",
       "995     (((tf.Tensor(0.19353554, shape=(), dtype=float...\n",
       "1970    (((tf.Tensor(0.16565947, shape=(), dtype=float...\n",
       "4393    (((tf.Tensor(0.19068627, shape=(), dtype=float...\n",
       "9842    (((tf.Tensor(0.7561275, shape=(), dtype=float3...\n",
       "Name: file_path, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_dataset.head())\n",
    "\n",
    "#print(train_dataset['file_path'])\n",
    "#display(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beb4559",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(5 * 5):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.title('Original image')\n",
    "    image =  train_dataset.iloc[i]\n",
    "    plt.imshow(image)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2414e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Side by side comparrison with the new ratio\n",
    "for i in range(5 * 5):\n",
    "    result_image = train_dataset.iloc[i]\n",
    "    train_image = plt.imread(train.iloc[i,-1])\n",
    "    visualize(train_image,result_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b2dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(augmented):\n",
    "    # We need to test with the diffrent type of augment to see if they hurt the acc. \n",
    "    # We should also take some of the fuctions we used in CNN\n",
    "    augmented = tf.image.random_brightness(augmented, 0.05)\n",
    "    augmented = tf.image.random_flip_left_right(augmented)\n",
    "    augmented = tf.image.random_saturation(augmented, 0.95, 1)\n",
    "    augmented = tf.image.random_contrast(augmented, 0.95, 1)\n",
    "    augmented = tf.image.random_hue(augmented, 0.05)\n",
    "    augmented = shear(augmented)\n",
    "    return augmented\n",
    "\n",
    "def visualize(original, augmented):\n",
    "    fig = plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('Original image')\n",
    "    plt.imshow(original)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('Augmented image')\n",
    "    plt.imshow(augmented)\n",
    "    \n",
    "def shear(image):\n",
    "    #shear\n",
    "    #de her værdier skal nok ændres i\n",
    "    random_number_shear = random.uniform(-0.2,0.2)\n",
    "    shear = random_number_shear\n",
    "    shear_rotate = shear * -20\n",
    "    image = tfa.image.transform(image, [1.0, shear, shear_rotate, 0.0, 1.0, 0.0, 0.0, 0.0])\n",
    "    return image\n",
    "\n",
    "def crop(image):\n",
    "    # Add 6 pixels of padding\n",
    "    image = tf.image.resize_with_crop_or_pad(image, img_height + 6, img_width + 6) \n",
    "    # Random crop back to the original size\n",
    "    image = tf.image.random_crop(image, size=[img_height, img_width, 1])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0fcbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    image = train_dataset.iloc[i]\n",
    "    changed_image = augment(image)\n",
    "    visualize(image,changed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "124b18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First model\n",
    "model = tf.keras.models.Sequential([\n",
    "layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
    "layers.Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "layers.MaxPool2D(pool_size=2, strides=2),\n",
    "layers.Dropout(0.25),\n",
    "layers.Conv2D(filters=128, kernel_size=3, activation='relu'),\n",
    "layers.MaxPool2D(pool_size=2, strides=2),\n",
    "layers.Conv2D(filters=128, kernel_size=3, activation='relu'),\n",
    "layers.MaxPool2D(pool_size=2, strides=2),\n",
    "layers.Dropout(0.25),\n",
    "layers.Flatten(),\n",
    "layers.Dense(units=1024, activation='relu'),\n",
    "layers.Dropout(0.50),\n",
    "layers.Dense(units=1,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.MeanSquaredError(),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad8c5794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(64, 64, 3), dtype=float32, numpy=\n",
      " array([[[0.26078433, 0.27254903, 0.30784315],\n",
      "         [0.23137255, 0.25882354, 0.2901961 ],\n",
      "         [0.2764706 , 0.30392158, 0.33529413],\n",
      "         ...,\n",
      "         [0.50784314, 0.4882353 , 0.46862745],\n",
      "         [0.59607846, 0.5529412 , 0.5411765 ],\n",
      "         [0.43333334, 0.38235295, 0.35882354]],\n",
      "\n",
      "        [[0.19019608, 0.21764706, 0.25686276],\n",
      "         [0.22352941, 0.23137255, 0.2901961 ],\n",
      "         [0.23333333, 0.24509804, 0.28039217],\n",
      "         ...,\n",
      "         [0.43333334, 0.39019608, 0.3745098 ],\n",
      "         [0.49019608, 0.44705883, 0.4392157 ],\n",
      "         [0.4       , 0.3529412 , 0.36078432]],\n",
      "\n",
      "        [[0.18039216, 0.1764706 , 0.23137255],\n",
      "         [0.20784314, 0.20784314, 0.25490198],\n",
      "         [0.23921569, 0.23921569, 0.28627452],\n",
      "         ...,\n",
      "         [0.5019608 , 0.48431373, 0.45490196],\n",
      "         [0.53137255, 0.47058824, 0.46078432],\n",
      "         [0.46078432, 0.40588236, 0.39803922]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.80196077, 0.79019606, 0.73137254],\n",
      "         [0.8       , 0.7882353 , 0.72156864],\n",
      "         [0.79019606, 0.77843136, 0.7117647 ],\n",
      "         ...,\n",
      "         [0.87058824, 0.84313726, 0.78039217],\n",
      "         [0.84705883, 0.81960785, 0.75686276],\n",
      "         [0.85490197, 0.827451  , 0.7647059 ]],\n",
      "\n",
      "        [[0.7882353 , 0.7764706 , 0.70980394],\n",
      "         [0.80588233, 0.7941176 , 0.72745097],\n",
      "         [0.80196077, 0.79019606, 0.7235294 ],\n",
      "         ...,\n",
      "         [0.87647057, 0.84117645, 0.80588233],\n",
      "         [0.85490197, 0.827451  , 0.7647059 ],\n",
      "         [0.85490197, 0.8254902 , 0.76862746]],\n",
      "\n",
      "        [[0.79607844, 0.78431374, 0.7176471 ],\n",
      "         [0.8       , 0.7882353 , 0.7294118 ],\n",
      "         [0.8039216 , 0.7921569 , 0.73333335],\n",
      "         ...,\n",
      "         [0.8745098 , 0.84117645, 0.80196077],\n",
      "         [0.8666667 , 0.8333333 , 0.7941176 ],\n",
      "         [0.8568627 , 0.8254902 , 0.7745098 ]]], dtype=float32)>\n",
      " <tf.Tensor: shape=(64, 64, 3), dtype=float32, numpy=\n",
      " array([[[0.19353554, 0.18189338, 0.30995712],\n",
      "         [0.21151961, 0.22328432, 0.34485295],\n",
      "         [0.2318321 , 0.2200674 , 0.34163603],\n",
      "         ...,\n",
      "         [0.4005333 , 0.14216931, 0.18107863],\n",
      "         [0.40388137, 0.1299843 , 0.16828087],\n",
      "         [0.40820217, 0.1212096 , 0.17012867]],\n",
      "\n",
      "        [[0.15925245, 0.13572304, 0.26965955],\n",
      "         [0.16954657, 0.17346814, 0.2911152 ],\n",
      "         [0.20528302, 0.18959674, 0.3190085 ],\n",
      "         ...,\n",
      "         [0.47322974, 0.14773954, 0.22617091],\n",
      "         [0.47447917, 0.12892157, 0.21519607],\n",
      "         [0.48027918, 0.13875134, 0.22383578]],\n",
      "\n",
      "        [[0.14739583, 0.13852347, 0.2308699 ],\n",
      "         [0.15794462, 0.14532207, 0.27549976],\n",
      "         [0.19748679, 0.18495615, 0.30805665],\n",
      "         ...,\n",
      "         [0.6334779 , 0.27823892, 0.38176125],\n",
      "         [0.46472502, 0.11980411, 0.23735926],\n",
      "         [0.5946873 , 0.22060643, 0.34686255]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.56123143, 0.49848634, 0.43966278],\n",
      "         [0.5449755 , 0.4822304 , 0.42340687],\n",
      "         [0.55079466, 0.48804957, 0.42530447],\n",
      "         ...,\n",
      "         [0.63691884, 0.6047804 , 0.58995193],\n",
      "         [0.4313687 , 0.36477387, 0.32553422],\n",
      "         [0.57063705, 0.51965666, 0.4882841 ]],\n",
      "\n",
      "        [[0.54585916, 0.4831141 , 0.420369  ],\n",
      "         [0.5565257 , 0.49378064, 0.43103555],\n",
      "         [0.5452991 , 0.482554  , 0.4198089 ],\n",
      "         ...,\n",
      "         [0.5254768 , 0.4747549 , 0.44364086],\n",
      "         [0.6923618 , 0.6607728 , 0.6491163 ],\n",
      "         [0.70813036, 0.6698338 , 0.6615311 ]],\n",
      "\n",
      "        [[0.5491422 , 0.48639706, 0.42365196],\n",
      "         [0.5764706 , 0.5137255 , 0.4509804 ],\n",
      "         [0.56993914, 0.507194  , 0.4483705 ],\n",
      "         ...,\n",
      "         [0.7442096 , 0.7246017 , 0.7089154 ],\n",
      "         [0.8011901 , 0.78158224, 0.76589596],\n",
      "         [0.8109538 , 0.79134595, 0.7756597 ]]], dtype=float32)>\n",
      " <tf.Tensor: shape=(64, 64, 3), dtype=float32, numpy=\n",
      " array([[[0.16565947, 0.18379672, 0.12619868],\n",
      "         [0.227338  , 0.22292624, 0.14473997],\n",
      "         [0.21072304, 0.19895834, 0.13572304],\n",
      "         ...,\n",
      "         [0.5100854 , 0.5331246 , 0.5600854 ],\n",
      "         [0.50535196, 0.48966566, 0.47790095],\n",
      "         [0.4311102 , 0.41542393, 0.40365922]],\n",
      "\n",
      "        [[0.17181373, 0.18995099, 0.13235295],\n",
      "         [0.21213235, 0.2077206 , 0.12953432],\n",
      "         [0.21496439, 0.20319968, 0.13996439],\n",
      "         ...,\n",
      "         [0.47062844, 0.49366766, 0.52062845],\n",
      "         [0.53011066, 0.5144244 , 0.5026597 ],\n",
      "         [0.42233646, 0.4066502 , 0.39488548]],\n",
      "\n",
      "        [[0.17390281, 0.19204006, 0.13444202],\n",
      "         [0.19656862, 0.19215687, 0.11397059],\n",
      "         [0.19935471, 0.18759   , 0.12435471],\n",
      "         ...,\n",
      "         [0.4090648 , 0.43210402, 0.4590648 ],\n",
      "         [0.46749386, 0.4518076 , 0.44004288],\n",
      "         [0.37904412, 0.36335784, 0.35159314]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7016908 , 0.70953393, 0.6899261 ],\n",
      "         [0.7347082 , 0.7425513 , 0.7229435 ],\n",
      "         [0.7382621 , 0.74610525, 0.7264974 ],\n",
      "         ...,\n",
      "         [0.50851715, 0.50885224, 0.4914254 ],\n",
      "         [0.5279718 , 0.5632659 , 0.55934435],\n",
      "         [0.60495746, 0.64025164, 0.63633007]],\n",
      "\n",
      "        [[0.56212085, 0.569964  , 0.5581993 ],\n",
      "         [0.5605028 , 0.56834596, 0.55658126],\n",
      "         [0.57093865, 0.5787818 , 0.5670171 ],\n",
      "         ...,\n",
      "         [0.5922315 , 0.59093136, 0.5804879 ],\n",
      "         [0.61436886, 0.649663  , 0.6457414 ],\n",
      "         [0.6539733 , 0.6892674 , 0.6853458 ]],\n",
      "\n",
      "        [[0.72374386, 0.731587  , 0.7276654 ],\n",
      "         [0.7415843 , 0.74942744, 0.74550587],\n",
      "         [0.7405025 , 0.7483456 , 0.74442405],\n",
      "         ...,\n",
      "         [0.6114698 , 0.6211397 , 0.6170343 ],\n",
      "         [0.6431373 , 0.6784314 , 0.6745098 ],\n",
      "         [0.6573529 , 0.69264704, 0.6887255 ]]], dtype=float32)> ...\n",
      " <tf.Tensor: shape=(64, 64, 3), dtype=float32, numpy=\n",
      " array([[[0.6057866 , 0.53714   , 0.50968903],\n",
      "         [0.48115042, 0.37526807, 0.30075827],\n",
      "         [0.4266544 , 0.32469362, 0.23449755],\n",
      "         ...,\n",
      "         [0.88235295, 0.88235295, 0.88235295],\n",
      "         [0.8752451 , 0.8752451 , 0.8752451 ],\n",
      "         [0.8733877 , 0.8733877 , 0.8733877 ]],\n",
      "\n",
      "        [[0.6547411 , 0.61018306, 0.5729933 ],\n",
      "         [0.4754404 , 0.35032934, 0.26089156],\n",
      "         [0.44381127, 0.3152765 , 0.22441024],\n",
      "         ...,\n",
      "         [0.88235295, 0.88235295, 0.88235295],\n",
      "         [0.88235295, 0.88235295, 0.88235295],\n",
      "         [0.8784314 , 0.8784314 , 0.8784314 ]],\n",
      "\n",
      "        [[0.5465456 , 0.46415824, 0.397595  ],\n",
      "         [0.51394   , 0.42648208, 0.3692134 ],\n",
      "         [0.44579887, 0.32660845, 0.24391085],\n",
      "         ...,\n",
      "         [0.88572305, 0.886826  , 0.8862745 ],\n",
      "         [0.8818015 , 0.8829044 , 0.88235295],\n",
      "         [0.881767  , 0.88286996, 0.8823185 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.649954  , 0.67348343, 0.67348343],\n",
      "         [0.7095971 , 0.7252834 , 0.72920495],\n",
      "         [0.72868794, 0.7443742 , 0.7561389 ],\n",
      "         ...,\n",
      "         [0.87395835, 0.8818015 , 0.8778799 ],\n",
      "         [0.8666667 , 0.8745098 , 0.87058824],\n",
      "         [0.8480392 , 0.85588235, 0.8519608 ]],\n",
      "\n",
      "        [[0.68082494, 0.7199142 , 0.7159926 ],\n",
      "         [0.72511107, 0.74079734, 0.7447189 ],\n",
      "         [0.75306374, 0.77254903, 0.77457106],\n",
      "         ...,\n",
      "         [0.8627451 , 0.87058824, 0.8666667 ],\n",
      "         [0.85882354, 0.8666667 , 0.8627451 ],\n",
      "         [0.85857844, 0.8664216 , 0.8625    ]],\n",
      "\n",
      "        [[0.7217716 , 0.7374579 , 0.74137944],\n",
      "         [0.737994  , 0.77328813, 0.76936656],\n",
      "         [0.76740193, 0.7830882 , 0.7870098 ],\n",
      "         ...,\n",
      "         [0.8627451 , 0.87058824, 0.8666667 ],\n",
      "         [0.8509804 , 0.85882354, 0.85490197],\n",
      "         [0.8502451 , 0.85808825, 0.8541667 ]]], dtype=float32)>\n",
      " <tf.Tensor: shape=(64, 64, 3), dtype=float32, numpy=\n",
      " array([[[0.74509805, 0.654902  , 0.46862745],\n",
      "         [0.80588233, 0.71960783, 0.5529412 ],\n",
      "         [0.84705883, 0.7647059 , 0.59607846],\n",
      "         ...,\n",
      "         [0.87058824, 0.78039217, 0.61960787],\n",
      "         [0.8686274 , 0.7823529 , 0.6215686 ],\n",
      "         [0.85490197, 0.76862746, 0.60784316]],\n",
      "\n",
      "        [[0.6901961 , 0.61960787, 0.5411765 ],\n",
      "         [0.75490195, 0.6607843 , 0.49803922],\n",
      "         [0.8254902 , 0.7352941 , 0.57058823],\n",
      "         ...,\n",
      "         [0.8686274 , 0.7823529 , 0.6215686 ],\n",
      "         [0.8666667 , 0.78039217, 0.61960787],\n",
      "         [0.85882354, 0.77254903, 0.6117647 ]],\n",
      "\n",
      "        [[0.15882353, 0.20784314, 0.26666668],\n",
      "         [0.7352941 , 0.6764706 , 0.5862745 ],\n",
      "         [0.65882355, 0.5686275 , 0.40784314],\n",
      "         ...,\n",
      "         [0.88235295, 0.79607844, 0.63529414],\n",
      "         [0.8745098 , 0.7882353 , 0.627451  ],\n",
      "         [0.86470586, 0.77843136, 0.61764705]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7509804 , 0.64509803, 0.53137255],\n",
      "         [0.7705882 , 0.6607843 , 0.56666666],\n",
      "         [0.74509805, 0.62352943, 0.5137255 ],\n",
      "         ...,\n",
      "         [0.6509804 , 0.50980395, 0.40784314],\n",
      "         [0.5509804 , 0.4372549 , 0.30392158],\n",
      "         [0.6117647 , 0.4745098 , 0.3529412 ]],\n",
      "\n",
      "        [[0.79607844, 0.6901961 , 0.58431375],\n",
      "         [0.70392156, 0.5686275 , 0.45882353],\n",
      "         [0.8039216 , 0.69803923, 0.58431375],\n",
      "         ...,\n",
      "         [0.6039216 , 0.45490196, 0.3137255 ],\n",
      "         [0.61764705, 0.4882353 , 0.3509804 ],\n",
      "         [0.5901961 , 0.47254902, 0.33529413]],\n",
      "\n",
      "        [[0.75686276, 0.63529414, 0.5254902 ],\n",
      "         [0.7294118 , 0.5921569 , 0.4745098 ],\n",
      "         [0.6960784 , 0.6019608 , 0.49215686],\n",
      "         ...,\n",
      "         [0.6333333 , 0.48039216, 0.35882354],\n",
      "         [0.5509804 , 0.4137255 , 0.2882353 ],\n",
      "         [0.5745098 , 0.44509804, 0.3156863 ]]], dtype=float32)>\n",
      " <tf.Tensor: shape=(64, 64, 3), dtype=float32, numpy=\n",
      " array([[[0.08480392, 0.10343137, 0.0759804 ],\n",
      "         [0.06372549, 0.0754902 , 0.04803922],\n",
      "         [0.03186275, 0.04362745, 0.01617647],\n",
      "         ...,\n",
      "         [0.00833333, 0.00833333, 0.00833333],\n",
      "         [0.00637255, 0.00637255, 0.00637255],\n",
      "         [0.00392157, 0.00392157, 0.00392157]],\n",
      "\n",
      "        [[0.4392157 , 0.45833334, 0.47009805],\n",
      "         [0.422549  , 0.42647058, 0.44607842],\n",
      "         [0.3509804 , 0.35490197, 0.37058824],\n",
      "         ...,\n",
      "         [0.01813726, 0.01813726, 0.01813726],\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00833333, 0.00833333, 0.00833333]],\n",
      "\n",
      "        [[0.34313726, 0.36960784, 0.33872548],\n",
      "         [0.29166666, 0.30343136, 0.26813725],\n",
      "         [0.24460784, 0.22009803, 0.19166666],\n",
      "         ...,\n",
      "         [0.00294118, 0.00294118, 0.00294118],\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.01176471, 0.01176471, 0.01176471]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7480392 , 0.7558824 , 0.7519608 ],\n",
      "         [0.69166666, 0.7318627 , 0.70980394],\n",
      "         [0.7294118 , 0.7294118 , 0.72156864],\n",
      "         ...,\n",
      "         [0.33039215, 0.32254902, 0.32647058],\n",
      "         [0.51911765, 0.5151961 , 0.50735295],\n",
      "         [0.6098039 , 0.60588235, 0.5862745 ]],\n",
      "\n",
      "        [[0.7132353 , 0.7289216 , 0.725     ],\n",
      "         [0.70735294, 0.7269608 , 0.7112745 ],\n",
      "         [0.71666664, 0.7362745 , 0.7205882 ],\n",
      "         ...,\n",
      "         [0.60833335, 0.63186276, 0.62892157],\n",
      "         [0.595098  , 0.61470586, 0.59117645],\n",
      "         [0.5921569 , 0.6284314 , 0.6230392 ]],\n",
      "\n",
      "        [[0.722549  , 0.73039216, 0.7264706 ],\n",
      "         [0.6970588 , 0.7323529 , 0.7205882 ],\n",
      "         [0.70735294, 0.7151961 , 0.7112745 ],\n",
      "         ...,\n",
      "         [0.54068625, 0.56666666, 0.54362744],\n",
      "         [0.62941176, 0.6490196 , 0.6607843 ],\n",
      "         [0.62647057, 0.6490196 , 0.6495098 ]]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "#print(train_dataset.shape)\n",
    "#type(train_dataset)\n",
    "#print(test_dataset.shape)\n",
    "#print(train_dataset)\n",
    "#def labelNormalize(value):\n",
    "#    return value/100;\n",
    "#train_pred = train_pred.map(labelNormalize)\n",
    "#test_pred = test_pred.map(labelNormalize)\n",
    "\n",
    "#print(train_dataset)\n",
    "#test_dataset.dtypes\n",
    "#tf.convert_to_tensor(train_dataset)\n",
    "#normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "#normalizer.adapt(train_dataset)\n",
    "X = np.array(train_dataset)\n",
    "Y = np.array(test_dataset)\n",
    "type(X)\n",
    "print(X)\n",
    "#clf.fit(test_dataset[0].tolist(), labels)\n",
    "#np.array(test_dataset).astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e07ab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)\n",
    "#print(train_dataset)\n",
    "#print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f27c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_dataset)\n",
    "#df[df['price'] < 50000]\n",
    "#https://www.kaggle.com/questions-and-answers/50121\n",
    "\n",
    "#train_dataset.loc[(train_dataset[\"Pawpularity\"]<=100)|train_dataset[\"Pawpularity\"]>0]\n",
    "#test_dataset.loc[(test_dataset[\"Pawpularity\"]<=100)|test_dataset[\"Pawpularity\"]>0]\n",
    "\n",
    "\n",
    "#intet virker og jeg er trist del op uden merge i x-y_pred\n",
    "#We need to batch the data aswell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafe5af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset,batch_size=32, epochs = 5)\n",
    "#fit(\n",
    "#    x=None, y=None, batch_size=None, epochs=1, verbose='auto',\n",
    "#    callbacks=None, validation_split=0.0, validation_data=None, shuffle=True,\n",
    "#    class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None,\n",
    "#    validation_steps=None, validation_batch_size=None, validation_freq=1,\n",
    "#    max_queue_size=10, workers=1, use_multiprocessing=False\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35891fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8cd962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
